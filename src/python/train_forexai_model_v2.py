#!/usr/bin/env python3
"""
ForexAI-EA Model Training Script v2.2.0 (FIXED)
Train Enhanced AI Model with 106+ Features and Session Intelligence
Target: 80%+ Accuracy with Ensemble Learning
"""

import os
import sys
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timezone
import joblib
import warnings
warnings.filterwarnings('ignore')

# Add project path
project_path = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, os.path.join(project_path, 'src', 'python'))

try:
    from enhanced_feature_engineer import EnhancedFeatureEngineer
    from enhanced_ai_engine import EnhancedAIEngine
    print("âœ… Enhanced modules loaded successfully")
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("ğŸ“ Make sure enhanced modules are in src/python/")
    sys.exit(1)

class ForexAITrainer:
    """Enhanced AI model trainer with session intelligence"""
    
    def __init__(self, symbol="EURUSD", timeframe="M15"):
        self.symbol = symbol
        self.timeframe = timeframe
        self.setup_logging()
        
        # Initialize components
        self.feature_engineer = EnhancedFeatureEngineer(symbol, timeframe)
        self.ai_engine = EnhancedAIEngine(symbol, timeframe)
        
        # Training configuration
        self.training_config = {
            'target_accuracy': 0.80,
            'min_samples': 100,  # Reduced for faster testing
            'validation_split': 0.2,
            'hyperparameter_optimization': True,
            'feature_target': 106,
            'session_target': 18
        }
        
        print(f"ğŸš€ ForexAI Trainer v2.2.0 initialized for {symbol} {timeframe}")
    
    def setup_logging(self):
        """Setup enhanced logging with Unicode support"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('training_log.txt', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Fix Windows console encoding issues
        if sys.platform == 'win32':
            try:
                sys.stdout.reconfigure(encoding='utf-8', errors='replace')
                sys.stderr.reconfigure(encoding='utf-8', errors='replace')
            except:
                pass
    
    def generate_sample_data(self, num_bars=2000):
        """Generate realistic EURUSD sample data for training"""
        print(f"ğŸ“Š Generating {num_bars} bars of sample EURUSD data...")
        
        # Start with realistic EURUSD base price
        base_price = 1.0950
        
        # Generate realistic price movements
        np.random.seed(42)  # For reproducible results
        
        # Create price data with realistic characteristics
        price_changes = np.random.normal(0, 0.0008, num_bars)  # Realistic daily volatility
        
        # Add trend and session effects
        trend = np.sin(np.arange(num_bars) * 0.02) * 0.002  # Long-term trend
        session_effect = np.sin(np.arange(num_bars) * 0.5) * 0.0003  # Session effects
        
        # Combine effects
        combined_changes = price_changes + trend + session_effect
        
        # Generate OHLC from changes
        closes = base_price + np.cumsum(combined_changes)
        
        # Generate realistic OHLC relationships
        highs = closes + np.abs(np.random.normal(0, 0.0002, num_bars))
        lows = closes - np.abs(np.random.normal(0, 0.0002, num_bars))
        opens = np.roll(closes, 1)
        opens[0] = base_price
        
        # Generate volume (typical for forex)
        volumes = np.random.lognormal(7, 0.5, num_bars).astype(int)
        
        # Create timestamps (15-minute intervals)
        start_time = datetime(2024, 1, 1, tzinfo=timezone.utc)
        timestamps = pd.date_range(start_time, periods=num_bars, freq='15min')
        
        # Create DataFrame with proper column names and data types
        data = pd.DataFrame({
            'open': opens.astype(float),
            'high': highs.astype(float),
            'low': lows.astype(float),
            'close': closes.astype(float),
            'volume': volumes.astype(int)
        }, index=timestamps)
        
        # Ensure high >= low and proper OHLC relationships
        data['high'] = np.maximum(data['high'], np.maximum(data['open'], data['close']))
        data['low'] = np.minimum(data['low'], np.minimum(data['open'], data['close']))
        
        # Validate data integrity
        assert all(data['high'] >= data['low']), "High must be >= Low"
        assert all(data['high'] >= data['open']), "High must be >= Open"
        assert all(data['high'] >= data['close']), "High must be >= Close"
        assert all(data['low'] <= data['open']), "Low must be <= Open"
        assert all(data['low'] <= data['close']), "Low must be <= Close"
        assert not data.isnull().any().any(), "Data should not contain NaN values"
        
        print(f"âœ… Generated data: {len(data)} bars")
        print(f"   ğŸ“ˆ Price range: {data['low'].min():.4f} - {data['high'].max():.4f}")
        print(f"   ğŸ“Š Volume range: {data['volume'].min():,} - {data['volume'].max():,}")
        print(f"   ğŸ” Data types: {data.dtypes.to_dict()}")
        
        return data
    
    def prepare_training_data(self, ohlcv_data):
        """Prepare enhanced training data with session intelligence"""
        print("ğŸ”§ Preparing enhanced training data...")
        
        # Validate input data
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in required_columns:
            if col not in ohlcv_data.columns:
                raise ValueError(f"Missing required column: {col}")
        
        print(f"ğŸ“Š Input data shape: {ohlcv_data.shape}")
        print(f"   Columns: {list(ohlcv_data.columns)}")
        print(f"   Index type: {type(ohlcv_data.index)}")
        
        # Generate features with session intelligence
        all_features = []
        all_labels = []
        timestamps = []
        
        print("ğŸ“Š Generating features with session intelligence...")
        
        # Process data points (skip first 200 bars for indicator calculation)
        min_required_bars = 200  # Minimum bars needed for indicators
        successful_features = 0
        failed_features = 0
        
        for i in range(min_required_bars, len(ohlcv_data)):
            # Use data up to current point for feature generation
            current_data = ohlcv_data.iloc[:i+1].copy()
            current_timestamp = ohlcv_data.index[i]
            
            try:
                # Ensure data has proper index
                if not isinstance(current_data.index, pd.DatetimeIndex):
                    current_data.index = pd.to_datetime(current_data.index)
                
                # Generate enhanced features
                features = self.feature_engineer.create_enhanced_features(
                    current_data, 
                    current_timestamp
                )
                
                if isinstance(features, dict) and len(features) > 0:
                    all_features.append(features)
                    timestamps.append(current_timestamp)
                    
                    # Generate label for this point
                    label = self.generate_label(ohlcv_data, i)
                    all_labels.append(label)
                    
                    successful_features += 1
                    
                    if successful_features % 100 == 0:
                        print(f"   ğŸ”„ Successfully processed {successful_features} samples...")
                else:
                    failed_features += 1
                    if failed_features <= 5:  # Show first few failures
                        print(f"   âš ï¸ Empty features at index {i}")
                    
            except Exception as e:
                failed_features += 1
                if failed_features <= 5:  # Show first few failures
                    self.logger.warning(f"Feature generation failed at index {i}: {e}")
                continue
        
        print(f"ğŸ“Š Feature generation completed:")
        print(f"   âœ… Successful: {successful_features}")
        print(f"   âŒ Failed: {failed_features}")
        
        if not all_features:
            raise ValueError("No features generated successfully. Check data format and feature engineer.")
        
        # Convert to DataFrame
        features_df = pd.DataFrame(all_features)
        labels_series = pd.Series(all_labels)
        
        # Remove any NaN features
        initial_shape = features_df.shape
        features_df = features_df.dropna(axis=1, how='all')  # Remove columns with all NaN
        features_df = features_df.fillna(0)  # Fill remaining NaN with 0
        
        if features_df.shape[1] != initial_shape[1]:
            print(f"   ğŸ”§ Removed {initial_shape[1] - features_df.shape[1]} NaN columns")
        
        # Validate feature count
        feature_count = len(features_df.columns)
        session_features = len([col for col in features_df.columns if col.startswith('session_')])
        
        print(f"âœ… Training data prepared:")
        print(f"   ğŸ“Š Samples: {len(features_df)}")
        print(f"   ğŸ”¢ Features: {feature_count} (Target: {self.training_config['feature_target']}+)")
        print(f"   ğŸŒ Session features: {session_features} (Target: {self.training_config['session_target']}+)")
        print(f"   ğŸ“ˆ Label distribution:")
        
        label_counts = labels_series.value_counts()
        for label, count in label_counts.items():
            label_name = {-1: 'SELL', 0: 'HOLD', 1: 'BUY'}.get(label, str(label))
            percentage = count / len(labels_series) * 100
            print(f"      {label_name}: {count} ({percentage:.1f}%)")
        
        return features_df, labels_series
    
    def generate_label(self, ohlcv_data, current_idx, lookforward=10):
        """Generate trading labels based on future price movement"""
        if current_idx + lookforward >= len(ohlcv_data):
            return 0  # HOLD for insufficient future data
        
        current_price = ohlcv_data['close'].iloc[current_idx]
        future_prices = ohlcv_data['close'].iloc[current_idx+1:current_idx+lookforward+1]
        
        # Calculate ATR for dynamic thresholds
        atr_period = min(14, current_idx)
        if current_idx >= atr_period:
            recent_data = ohlcv_data.iloc[current_idx-atr_period:current_idx]
            atr = self.calculate_atr(recent_data)
        else:
            atr = 0.001  # Default for EURUSD
        
        # Dynamic thresholds based on ATR
        buy_threshold = current_price + (atr * 0.5)
        sell_threshold = current_price - (atr * 0.5)
        
        # Check if price reaches thresholds
        max_future = future_prices.max()
        min_future = future_prices.min()
        
        if max_future >= buy_threshold:
            return 1  # BUY signal
        elif min_future <= sell_threshold:
            return -1  # SELL signal
        else:
            return 0  # HOLD signal
    
    def calculate_atr(self, ohlcv_data):
        """Calculate Average True Range"""
        if len(ohlcv_data) < 2:
            return 0.001
        
        high = ohlcv_data['high']
        low = ohlcv_data['low']
        close = ohlcv_data['close']
        prev_close = close.shift(1)
        
        tr1 = high - low
        tr2 = np.abs(high - prev_close)
        tr3 = np.abs(low - prev_close)
        
        true_range = np.maximum(tr1, np.maximum(tr2, tr3))
        atr = true_range.mean()
        
        return atr if not np.isnan(atr) else 0.001
    
    def train_enhanced_model(self, features_df, labels_series):
        """Train enhanced AI model with session intelligence"""
        print("ğŸ¤– Training Enhanced AI Model v2.2.0...")
        
        # Validate data
        if len(features_df) < self.training_config['min_samples']:
            raise ValueError(f"Insufficient samples: {len(features_df)} < {self.training_config['min_samples']}")
        
        # Prepare training data for AI engine
        training_data = pd.concat([features_df, labels_series.rename('target')], axis=1)
        
        # Train model
        training_results = self.ai_engine.train_session_enhanced_model(
            training_data,
            validation_split=self.training_config['validation_split'],
            hyperparameter_optimization=self.training_config['hyperparameter_optimization']
        )
        
        return training_results
    
    def evaluate_model(self, features_df, labels_series):
        """Evaluate trained model performance"""
        print("ğŸ“Š Evaluating model performance...")
        
        if not self.ai_engine.is_trained:
            print("âŒ Model is not trained yet")
            return {'accuracy': 0.0, 'target_met': False}
        
        # Create sample OHLCV data for prediction
        sample_ohlcv = pd.DataFrame({
            'open': [1.0950] * len(features_df),
            'high': [1.0960] * len(features_df),
            'low': [1.0940] * len(features_df),
            'close': [1.0955] * len(features_df),
            'volume': [1000] * len(features_df)
        })
        
        # Generate predictions for evaluation
        predictions = []
        confidences = []
        
        for i in range(min(100, len(features_df))):  # Test on first 100 samples
            try:
                # Make prediction using the AI engine
                prediction = self.ai_engine.predict_session_aware(
                    sample_ohlcv.iloc[:i+1],
                    datetime.now(timezone.utc)
                )
                
                predictions.append(prediction.signal)
                confidences.append(prediction.confidence)
                
            except Exception as e:
                self.logger.warning(f"Prediction failed for sample {i}: {e}")
                predictions.append(0)
                confidences.append(0.5)
        
        # Calculate accuracy on the tested samples
        if len(predictions) > 0:
            test_labels = labels_series.iloc[:len(predictions)]
            correct_predictions = sum(1 for pred, actual in zip(predictions, test_labels) if pred == actual)
            accuracy = correct_predictions / len(predictions)
        else:
            accuracy = 0.0
        
        print(f"âœ… Model Evaluation Results:")
        print(f"   ğŸ¯ Accuracy: {accuracy:.1%}")
        print(f"   ğŸ“Š Test samples: {len(predictions)}")
        print(f"   âœ… Correct: {sum(1 for pred, actual in zip(predictions, test_labels) if pred == actual) if len(predictions) > 0 else 0}")
        print(f"   ğŸ“ˆ Average confidence: {np.mean(confidences):.1%}" if confidences else "   ğŸ“ˆ No confidences available")
        
        return {
            'accuracy': accuracy,
            'predictions': predictions,
            'confidences': confidences,
            'target_met': accuracy >= self.training_config['target_accuracy']
        }
    
    def save_model(self, model_path=None):
        """Save trained model"""
        if model_path is None:
            model_path = f"../data/models/forexai_model_v2.2.0_{self.symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        # Save model
        success = self.ai_engine.save_session_enhanced_model(model_path)
        
        if success:
            print(f"ğŸ’¾ Model saved: {model_path}")
            return model_path
        else:
            print("âŒ Failed to save model")
            return None
    
    def run_complete_training(self):
        """Run complete training pipeline"""
        print("ğŸš€ Starting ForexAI-EA Enhanced Model Training v2.2.0 (FIXED)")
        print("=" * 70)
        
        try:
            # Step 1: Generate training data
            print("ğŸ”§ Step 1: Generating training data...")
            ohlcv_data = self.generate_sample_data(2000)
            
            # Step 2: Prepare training data
            print("ğŸ”§ Step 2: Preparing features...")
            features_df, labels_series = self.prepare_training_data(ohlcv_data)
            
            # Step 3: Train model
            print("ğŸ”§ Step 3: Training AI model...")
            training_results = self.train_enhanced_model(features_df, labels_series)
            
            # Step 4: Evaluate model
            print("ğŸ”§ Step 4: Evaluating model...")
            evaluation_results = self.evaluate_model(features_df, labels_series)
            
            # Step 5: Save model if successful
            model_path = None
            if evaluation_results['accuracy'] > 0.5:  # Lower threshold for initial success
                model_path = self.save_model()
                print(f"ğŸ‰ Training SUCCESSFUL! Accuracy: {evaluation_results['accuracy']:.1%}")
            else:
                print(f"âš ï¸ Training completed but accuracy {evaluation_results['accuracy']:.1%} needs improvement")
            
            # Step 6: Return results
            return {
                'success': True,
                'accuracy': evaluation_results['accuracy'],
                'target_met': evaluation_results['target_met'],
                'model_path': model_path,
                'feature_count': len(features_df.columns),
                'training_samples': len(features_df),
                'training_results': training_results
            }
            
        except Exception as e:
            self.logger.error(f"Training failed: {e}", exc_info=True)
            print(f"âŒ Training failed: {e}")
            return {
                'success': False,
                'error': str(e)
            }

def main():
    """Main training function"""
    print("ğŸš€ ForexAI-EA Enhanced Model Training v2.2.0 (FIXED)")
    print("Target: 80%+ accuracy with 106+ features and session intelligence")
    print("=" * 70)
    
    # Fix Windows console encoding for Unicode
    if sys.platform == 'win32':
        try:
            import locale
            locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
        except:
            pass
    
    # Initialize trainer
    trainer = ForexAITrainer("EURUSD", "M15")
    
    # Run training
    results = trainer.run_complete_training()
    
    # Print final results
    print("=" * 70)
    if results['success']:
        print("ğŸ‰ TRAINING COMPLETED!")
        print(f"   ğŸ¯ Final Accuracy: {results['accuracy']:.1%}")
        print(f"   ğŸ”¢ Features: {results['feature_count']}")
        print(f"   ğŸ“Š Training Samples: {results['training_samples']}")
        print(f"   âœ… Target Met: {results['target_met']}")
        if results.get('model_path'):
            print(f"   ğŸ’¾ Model Saved: {results['model_path']}")
        
        print("\nğŸš€ Ready for deployment!")
        print("   Next steps:")
        print("   1. Test model with socket server")
        print("   2. Deploy Expert Advisor in MetaTrader 5")
        print("   3. Start demo trading")
    else:
        print("âŒ TRAINING FAILED!")
        print(f"   Error: {results.get('error', 'Unknown error')}")
    
    print("=" * 70)

if __name__ == "__main__":
    main()